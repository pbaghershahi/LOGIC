method: logic
llm_model: meta-llama/Meta-Llama-3.1-8B-Instruct
eval_step: 10
gamma: 0.5
gnn_batch_size: 64
gnn_dropout: 0.4
gnn_eval_step: 10
gnn_gamma: 0.5
gnn_h_dim: 64
gnn_lr: 0.01
gnn_num_epochs: 100
gnn_num_hid_layers: 3
gnn_decoder_type: linear
gnn_step_size: 50
gnn_type: gcn
gnn_weight_decay: 0.0005
gnn_task_mode: node
projector_lr: 0.001
projector_step_size: 50
projector_num_epochs: 400
projector_weight_decay: 0.0
projector_gamma: 0.7
contrastive_temperature: 0.2
num_runs: 2
dataset: products
seed: 
- 4978
normal_mode: na
max_num_frequent_words: 2000
dataset_sample_size: 1000
max_num_eval_nodes: 200
gnn_dataloader_num_workers: 0
neighborhood_max_hops: 2
total_iters: 1
num_tokens: 5
llm_batch_size: 32
projector_contrastive_w: 0.5
projector_context_w: 1.0
projector_mutualinfo_w: 1.0
llm_node_batch_size: 5
save_generation_every: 10
use_bow: true
gnn_with_last_dropout: false
write_new_output: true
dataset_random_sampling: false
projector_with_backward: true
add_descriptive_prompt: false
train_test_split:
- 0.60
- 0.30